{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd60d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なモジュールをインポート\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def main():\n",
    "    # 環境変数の取得\n",
    "    load_dotenv(\"../.env\")\n",
    "    # os.environ['OPENAI_API_KEY'] = os.environ['API_KEY']\n",
    "    os.environ['OPENAI_API_KEY'] = load_api_key()\n",
    "\n",
    "    # モデル名\n",
    "    MODEL_NAME = \"gpt-4o-mini\"\n",
    "\n",
    "    # Indexの構築\n",
    "    documents = SimpleDirectoryReader('./data/text').load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "    # Chat Engineの作成\n",
    "    llm = OpenAI(model=MODEL_NAME)\n",
    "    chat_engine = generate_chat_engine(llm, index)\n",
    "\n",
    "    # チャットの例 (単発)\n",
    "    # response = chat_engine.stream_chat(\"公共交通機関の交通費の上限は？\")\n",
    "    # for token in response.response_gen:\n",
    "    #     print(token, end=\"\")\n",
    "\n",
    "    # チャットの開始\n",
    "    while(True):\n",
    "        message = input(\"メッセージを入力:\")\n",
    "        if message.strip()==\"\":\n",
    "            break\n",
    "\n",
    "        # jupyter 専用の関数なので純粋な Python では動作しないかも\n",
    "        display(f\"質問:{message}\")\n",
    "\n",
    "        # 質問（以下にソースコードを記述）\n",
    "        response = chat_engine.stream_chat(message)\n",
    "\n",
    "        # 回答を表示（以下にソースコードを記述）\n",
    "        for token in response.response_gen:\n",
    "            print(token, end=\"\", flush=True)\n",
    "        print(\"\")\n",
    "\n",
    "        # 引用元を表示\n",
    "        for source in response.sources:\n",
    "            for i, source_node in enumerate(source.raw_output.source_nodes):\n",
    "                print(\"\\033[37m\")\n",
    "                print(f\"===== 引用情報{1+i:02d} =====================\")\n",
    "                print(\"ファイル名：\", source_node.metadata[\"file_name\"])\n",
    "                print(\"関連度スコア:\", source_node.score)\n",
    "                print(\"テキスト：\")\n",
    "                print(source_node.node.text)\n",
    "                print(f\"===================================\")\n",
    "                print(\"\\033[0m\")\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n---ご利用ありがとうございました！---\")\n",
    "\n",
    "\n",
    "# テンプレートを有効化した chatbot をつくる\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import ChatPromptTemplate\n",
    "def generate_chat_engine(llm, index):\n",
    "\n",
    "    sys_prompt_str = \"\"\"\\\n",
    "事前知識ではなく、常に提供されたコンテキスト情報を使用して質問に回答してください。\n",
    "回答内でコンテキストを直接参照しないでください。\n",
    "「コンテキストに基づいて」や「コンテキスト情報は」、またはそれに類するような記述は避けてください。\n",
    "\"\"\"\n",
    "\n",
    "    qa_prompt_str = \"\"\"\\\n",
    "コンテキスト情報は以下の通りです。\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "事前知識ではなくコンテキスト情報を使用して、質問に回答してください。\n",
    "質問: {query_str}\n",
    "回答：\"\"\"\n",
    "\n",
    "    refine_prompt_str = \"\"\"\\\n",
    "元の回答を (必要な場合のみ) 以下のコンテキストで改良する機会があります。\n",
    "-----------\n",
    "{context_msg}\n",
    "-----------\n",
    "新しいコンテキストが与えられた場合、元の回答を改良して、質問 {query_str} に適切に回答します。\n",
    "コンテキストが役に立たない場合は、元の回答を再度出力します。\n",
    "元の回答: {existing_answer}\"\"\"\n",
    "\n",
    "    # テキストQAテンプレートの作成\n",
    "    chat_text_qa_msgs = [\n",
    "        ChatMessage(\n",
    "            role=MessageRole.SYSTEM,\n",
    "            content=sys_prompt_str),\n",
    "        ChatMessage(\n",
    "            role=MessageRole.USER,\n",
    "            content=qa_prompt_str),\n",
    "        ]\n",
    "    text_qa_template = ChatPromptTemplate(chat_text_qa_msgs)\n",
    "            \n",
    "    # リファインテンプレートの作成\n",
    "    chat_refine_msgs = [\n",
    "        ChatMessage(\n",
    "            role=MessageRole.SYSTEM,\n",
    "            content=sys_prompt_str),\n",
    "        ChatMessage(\n",
    "            role=MessageRole.USER,\n",
    "            content=refine_prompt_str),\n",
    "        ]\n",
    "    \n",
    "    refine_template = ChatPromptTemplate(chat_refine_msgs)\n",
    "\n",
    "    chat_engine = index.as_chat_engine(\n",
    "        chat_mode=\"openai\",\n",
    "        llm=llm,\n",
    "        similarity_top_k=3,\n",
    "        text_qa_template=text_qa_template,\n",
    "        refine_template=refine_template,\n",
    "    )\n",
    "\n",
    "    return chat_engine\n",
    "\n",
    "\n",
    "# 上手く鍵を読み取れない時があるので代わりに以下で無理やり取得しています ...\n",
    "def load_api_key():\n",
    "    api_key = None\n",
    "\n",
    "    # 1. ../.env を読み取る\n",
    "    env_file_path = Path().resolve().parent.resolve() / \".env\"\n",
    "    if env_file_path.is_file():\n",
    "        try:\n",
    "            load_dotenv(env_file_path)\n",
    "        except:\n",
    "            raise Exception(\"Found .env file but failed to load dotenv file! Please install python-dotenv module.\")\n",
    "\n",
    "    # 2. API_KEY を読み取る\n",
    "    api_key = os.environ.get(\"API_KEY\", None)\n",
    "\n",
    "    # 3. API_KEY の中身チェック\n",
    "    api_file_path = Path(api_key).expanduser()\n",
    "    if (api_file_path.is_absolute() and api_file_path.is_file()):\n",
    "        with open(api_file_path, \"r\") as f:\n",
    "            api_key = f.read().strip()\n",
    "\n",
    "    # 4. キーの簡易チェック\n",
    "    if re.match(r\"^sk\\-.*$\", api_key) is None:\n",
    "        raise Exception(\"Failed to load api key!\")\n",
    "        \n",
    "    return api_key\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
