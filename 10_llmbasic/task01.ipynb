{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84719e82",
   "metadata": {},
   "source": [
    "### Note.\n",
    "\n",
    "このファイルだけでは動作しないため  \n",
    "同じディレクトリに `chatbot_system_role.md` を配備してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbef88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### =======================================\n",
    "### ライブラリについて\n",
    "### =======================================\n",
    "\n",
    "# builtin modules\n",
    "import os                 # ... 環境変数をロードするために使います\n",
    "import re                 # ... 正規表現を利用して文字列をチェックするために使います\n",
    "from pathlib import Path  # ... (抽象的で)高度な Path 周りの関数を扱うために使います\n",
    "import traceback          # ... 主に例外のトレースバックを出力するデバッグ用途に用います\n",
    "\n",
    "# 3rd party modules\n",
    "from openai import OpenAI\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "### =======================================\n",
    "### メインの実装部分\n",
    "### =======================================\n",
    "\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "DEBUG_FLAG = False         # ... True にすると Debug モードになります、ログを出力します\n",
    "KEEP_MESSAGE_LIMIT = 3     # ... 直近過去何往復のやりとりまで記憶して送信するかです\n",
    "SYSTEM_ROLE_MESSAGE_PATH = Path(\".\") / \"chatbot_system_role.md\" \n",
    "                           # ... システムロールの指示を記載したファイルです\n",
    "\n",
    "def main():\n",
    "    # API キーを自動的にロードして OpenAI API クライアントを作る\n",
    "    client = OpenAIClientGenerator.generate(display_debug_messages=DEBUG_FLAG)\n",
    "\n",
    "    # ロギング用の関数 (デバッグ用に使います)\n",
    "    log = OpenAIClientGenerator.get_logger(DEBUG_FLAG)\n",
    "\n",
    "    # システム Role 用のメッセージ\n",
    "    # chatbot_system_role.md をロードします\n",
    "    with open(SYSTEM_ROLE_MESSAGE_PATH, \"r\") as f:\n",
    "        system_role_content = f.read().strip()\n",
    "    system_role_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_role_content\n",
    "    }\n",
    "\n",
    "    # メッセージを格納するリスト\n",
    "    user_messages = []\n",
    "\n",
    "    log(\"Started main program.\")\n",
    "    while(True):\n",
    "        # ユーザーからの質問を受付\n",
    "        message = input(\"メッセージを入力:\")\n",
    "\n",
    "        # 質問が入力されなければ終了\n",
    "        if message.strip() == \"\": break\n",
    "        print(f\"質問:{message}\")\n",
    "\n",
    "        # メッセージにユーザーからの質問を追加\n",
    "        user_messages.append({\"role\": \"user\", \"content\": message.strip()})\n",
    "\n",
    "        # やりとりが 2 * KEEP_MESSAGE_LIMIT を超えたら古いメッセージから削除\n",
    "        if len(user_messages) > (2 * KEEP_MESSAGE_LIMIT):\n",
    "            del_message = user_messages.pop(0)\n",
    "            log(f\"Deleted message. { del_message }\")\n",
    "\n",
    "        # APIへリクエスト\n",
    "        messages = [ system_role_message ] + user_messages\n",
    "        log(f\"Requesting API. model={MODEL_NAME} {messages=}\")\n",
    "        stream = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=messages,\n",
    "            stream=True,\n",
    "        )\n",
    "\n",
    "        # 言語モデルからの回答を表示\n",
    "        print(\"\\033[34m\", end=\"\")\n",
    "        response_message = \"\"\n",
    "        for chunk in stream:\n",
    "            if chunk.choices:\n",
    "                next = chunk.choices[0].delta.content\n",
    "                if next is not None:\n",
    "                    response_message += next\n",
    "                    print(next, end='', flush=True)\n",
    "        print(\"\\033[0m\")\n",
    "\n",
    "        # メッセージに言語モデルからの回答を追加\n",
    "        user_messages.append({\"role\": \"assistant\", \"content\": response_message})\n",
    "        log(f\"Stored answer. {response_message=} {user_messages=}\")\n",
    "\n",
    "    print(\"\\n---ご利用ありがとうございました！---\")\n",
    "    log(\"Finished main program.\")\n",
    "\n",
    "\n",
    "### =======================================\n",
    "### 以下、ユーティリティクラスとなります\n",
    "### =======================================\n",
    "\n",
    "\n",
    "class OpenAIClientGenerator:\n",
    "\n",
    "    OPEN_API_ENV_NAME = \"API_KEY\"\n",
    "    \n",
    "    # この関数を呼び出すことで .env ファイルもしくは環境変数から OpenAI API をロードして\n",
    "    # OpenAI の client インスタンスを返します\n",
    "    # api_key_validation      ... True なら簡易的なキーのチェックを行います\n",
    "    # display_debug_messages  ... True ならデバッグメッセージを表示します\n",
    "    @classmethod\n",
    "    def generate(cls, api_key_validation=True, display_debug_messages=False):\n",
    "        return OpenAI(api_key=cls.__load_api_key(api_key_validation, display_debug_messages))\n",
    "\n",
    "\n",
    "    # この関数で OpenAI API のキーを読み取ります\n",
    "    # 1. 実行パスの ../.env が存在するならば API_KEY を環境変数としてロードして読み取る\n",
    "    # 2. 環境変数の API_KEY をロードして読み取る\n",
    "    # 3. API_KEY の中身の値が絶対ファイルパスならばその中身をそのままロードする\n",
    "    #    そうでないならば中身をそのまま API キーとして使う\n",
    "    # 4. キーの簡易的なフォーマットチェック\n",
    "    @classmethod\n",
    "    def __load_api_key(cls, api_key_validation, display_debug_messages):        \n",
    "        api_key = None\n",
    "\n",
    "        log = cls.get_logger(display_debug_messages)\n",
    "\n",
    "        # 1. ../.env を読み取る\n",
    "        env_file_path = Path().resolve().parent.resolve() / \".env\"\n",
    "        if env_file_path.is_file():\n",
    "            try:\n",
    "                from dotenv import load_dotenv\n",
    "                load_dotenv(env_file_path)\n",
    "                log(f\"Loaded .env environment variables correctly. env={env_file_path.resolve()}\")\n",
    "            except:\n",
    "                log(\"=== EXCEPTION ============\")\n",
    "                log(traceback.format_exc())\n",
    "                log(\"==========================\")\n",
    "                log(\"Found .env file but failed to load dotenv file! Please install python-dotenv module.\")\n",
    "        \n",
    "        # 2. API_KEY を読み取る\n",
    "        api_key = os.environ.get(cls.OPEN_API_ENV_NAME, None)\n",
    "\n",
    "        # 3. API_KEY の中身チェック\n",
    "        api_file_path = Path(api_key).expanduser()\n",
    "        if (api_file_path.is_absolute() and api_file_path.is_file()):\n",
    "            log(\"Found OpenAI API key file.\")\n",
    "            with open(api_file_path, \"r\") as f:\n",
    "                api_key = f.read().strip()\n",
    "\n",
    "        # 4. キーの簡易チェック\n",
    "        if api_key_validation:\n",
    "            if re.match(r\"^sk\\-.*$\", api_key) is None:\n",
    "                raise Exception(\"Failed to load api key!\")\n",
    "\n",
    "        return api_key\n",
    "\n",
    "    \n",
    "    # 簡易 logging クラス代わり、ロガーを入手するための関数\n",
    "    @classmethod\n",
    "    def get_logger(cls, display_debug_messages):\n",
    "        return cls.log_print if display_debug_messages else (lambda *arg, **kwargs: None)\n",
    "\n",
    "\n",
    "    # 簡易 logging クラス代わり、ロガーで印字する関数\n",
    "    @staticmethod\n",
    "    def log_print(msg, *args, **kwargs):\n",
    "        formated_msg = f\"[LOG] {msg}\"\n",
    "        print(formated_msg, *args, **kwargs)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
