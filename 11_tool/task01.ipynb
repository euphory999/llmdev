{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84719e82",
   "metadata": {},
   "source": [
    "### Note.\n",
    "\n",
    "このファイルだけでは動作しないため  \n",
    "同じディレクトリに `chatbot_system_role.md` を配備してください\n",
    "\n",
    "自己学習のために計算ができるツールを追加しています……  \n",
    "こちらはレビュー外としていただいて問題ございません"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbef88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### =======================================\n",
    "### ライブラリについて\n",
    "### =======================================\n",
    "\n",
    "# builtin modules\n",
    "import os                 # ... 環境変数をロードするために使います\n",
    "import re                 # ... 正規表現を利用して文字列をチェックするために使います\n",
    "from pathlib import Path  # ... (抽象的で)高度な Path 周りの関数を扱うために使います\n",
    "import traceback          # ... 主に例外のトレースバックを出力するデバッグ用途に用います\n",
    "import json\n",
    "\n",
    "# 3rd party modules\n",
    "from openai import OpenAI\n",
    "from openai.types.chat import ChatCompletionToolParam\n",
    "from tavily import TavilyClient\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "### =======================================\n",
    "### メインの実装部分\n",
    "### =======================================\n",
    "\n",
    "MODEL_NAME = \"gpt-4o-mini\"\n",
    "DEBUG_FLAG = False         # ... True にすると Debug モードになります、ログを出力します\n",
    "KEEP_MESSAGE_LIMIT = 3     # ... 直近過去何往復のやりとりまで記憶して送信するかです\n",
    "SYSTEM_ROLE_MESSAGE_PATH = Path(\".\") / \"chatbot_system_role.md\" \n",
    "                           # ... システムロールの指示を記載したファイルです\n",
    "\n",
    "def main():\n",
    "    # API キーを自動的にロードして OpenAI API クライアントを作る\n",
    "    client = OpenAIClientGenerator.generate(display_debug_messages=DEBUG_FLAG)\n",
    "\n",
    "    # システム Role 用のメッセージ\n",
    "    # chatbot_system_role.md をロードします\n",
    "    with open(SYSTEM_ROLE_MESSAGE_PATH, \"r\") as f:\n",
    "        system_role_content = f.read().strip()\n",
    "    system_role_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_role_content\n",
    "    }\n",
    "\n",
    "    # メッセージを格納するリスト\n",
    "    user_questions = []\n",
    "\n",
    "    # ツール定義\n",
    "    tools = define_tools()\n",
    "\n",
    "    glog(\"Started main program.\")\n",
    "    while(True):\n",
    "        # ユーザーからの質問を受付\n",
    "        question = input(\"メッセージを入力:\").strip()\n",
    "\n",
    "        # 質問が入力されなければ終了\n",
    "        if question == \"\": break\n",
    "        print(f\"質問:{question}\")\n",
    "\n",
    "        # メッセージにユーザーからの質問を追加\n",
    "        user_questions.append({ \n",
    "            \"role\": \"user\",\n",
    "            \"content\": question\n",
    "        })\n",
    "\n",
    "        # やりとりが 2 * KEEP_MESSAGE_LIMIT を超えたら古いメッセージから削除\n",
    "        if len(user_questions) > (2 * KEEP_MESSAGE_LIMIT):\n",
    "            del_message = user_questions.pop(0)\n",
    "            glog(f\"Deleted message. { del_message }\")\n",
    "\n",
    "        # 言語モデルに質問\n",
    "        user_questions = [ system_role_message ] + user_questions\n",
    "        response_message, function_name = process_response(client, user_questions, tools)\n",
    "\n",
    "        # 言語モデルからの回答を表示\n",
    "        if function_name is None:\n",
    "            print(\"\\033[34m\" + response_message + \"\\033[0m\", flush=True)\n",
    "        else:\n",
    "            print(f\"\\033[1;30;43m 外部ツールを起動しました { function_name } \\033[0m\")\n",
    "            print(\"\\033[33m\" + response_message + \"\\033[0m\", flush=True)\n",
    "\n",
    "        # メッセージに言語モデルからの回答を追加\n",
    "        user_questions.append({\"role\": \"assistant\", \"content\": response_message})\n",
    "        glog(f\"Stored answer. {response_message=} {user_questions=}\")\n",
    "\n",
    "    print(\"\\n---ご利用ありがとうございました！---\")\n",
    "    glog(\"Finished main program.\")\n",
    "\n",
    "\n",
    "# ユーザーからの質問を処理する関数\n",
    "# Note. 外部関数として OpenAI client を受け取れるように第一引数 client を追加します\n",
    "#       返り値に「ツール呼出」を使った場合の関数名を返します、使っていない場合は None となります\n",
    "def process_response(client, question, tools):\n",
    "    # 言語モデルに質問を行い、言語モデルが「ツール呼出」か「言語モデルが直接回答する」かを決めます\n",
    "    response = ask_question(client, question, tools)\n",
    "\n",
    "    # 回答の内容によって「ツール呼出」か「言語モデルが直接回答する」か分岐\n",
    "    if response.choices[0].finish_reason == 'tool_calls':\n",
    "        # ツール呼出の場合\n",
    "        final_response, function_name = handle_tool_call(client, response, question)\n",
    "        return final_response.choices[0].message.content.strip(), function_name\n",
    "    else:\n",
    "        # 言語モデルが直接回答する場合\n",
    "        return response.choices[0].message.content.strip(), None\n",
    "\n",
    "\n",
    "# 言語モデルへの質問を行う関数\n",
    "# Note. 外部関数として OpenAI client を受け取れるように第一引数 client を追加します\n",
    "def ask_question(client, question, tools):\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=question,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "# ツール呼び出しが必要な場合の処理を行う関数\n",
    "# Note. 外部関数として OpenAI client を受け取れるように第一引数 client を追加します\n",
    "#       返り値に利用した「ツール呼出」の function_name (\"get_search_result\" など) を追加します\n",
    "def handle_tool_call(client, response, question):\n",
    "    # 関数の実行と結果取得\n",
    "    tool = response.choices[0].message.tool_calls[0]\n",
    "    function_name = tool.function.name\n",
    "    arguments = json.loads(tool.function.arguments) # API の返却値は JSON 文字列 なので <dict> に変換するのを忘れない\n",
    "    tool_function = globals().get(function_name, None) # ツール呼出の関数を取得できるならば取得する\n",
    "\n",
    "    glog(f\"Invoking external tool function. {function_name=} {arguments=}\")\n",
    "\n",
    "    # 実際にツールを呼び出す\n",
    "    if tool_function is not None:\n",
    "        function_response = tool_function(**arguments)\n",
    "        glog(f\"Invoked xternal tool function correctly. {function_response=}\")\n",
    "    else:\n",
    "        # 今回エラー処理は以下の Exception だけにさせていただきます ...\n",
    "        glog(f\"Failed to found tool function. {function_name=} {tool_function=}\")\n",
    "        raise Exception(f\"Failed to found tool function. {function_name=} {tool_function=}\")\n",
    "\n",
    "    # 言語モデルを呼出すためのメッセージを構築\n",
    "    messages = [ q for q in question ]           # 今までの会話履歴 (システムロールを含みます)\n",
    "    messages.append(response.choices[0].message) # 1次回答の中身 (中身はオブジェクト? 混合もOK?)\n",
    "    messages.append({                            # ツール呼出の結果\n",
    "        \"tool_call_id\": tool.id,\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": function_response,\n",
    "    })\n",
    "\n",
    "    # 関数の実行結果をmessagesに加えて再度言語モデルを呼出\n",
    "    response_after_tool_call = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    glog(f\"Handled tool correctly. {function_name=}\")\n",
    "    return response_after_tool_call, function_name\n",
    "\n",
    "\n",
    "### =======================================\n",
    "### 外部ツールの実装部分\n",
    "### =======================================\n",
    "\n",
    "# ツール定義\n",
    "def define_tools():\n",
    "    print(\"------define_tools(ツール定義)------\")\n",
    "    return [\n",
    "        ChatCompletionToolParam({\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_search_result\", # ---> ツールの関数名\n",
    "                \"description\": \"最近一ヵ月のイベント開催予定などネット検索が必要な場合に、質問文の検索結果を取得する\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"question\": { # ---> 関数へ引き渡す引数\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"質問文\"\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [ \"question\" ], # ---> 引数が必須かどうか\n",
    "                },\n",
    "            },\n",
    "        }),\n",
    "\n",
    "        # 自分の勉強のために文字列から計算を行うようなツールを追加させていただきます……\n",
    "        ChatCompletionToolParam({\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"local_calc\", # ---> ツールの関数名\n",
    "                \"description\": \"ユーザから計算式が与えられたときに、計算式だけを抽出することで計算結果を得ることができます、ただし変数は代入してください\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"expression\": { # ---> 関数へ引き渡す引数\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"ユーザから与えられた質問で変数を埋め込んだ計算式のみを抽出したものです、計算式はPythonで表現してください\"\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [ \"expression\" ], # ---> 引数が必須かどうか\n",
    "                },\n",
    "            },\n",
    "        })\n",
    "    ]\n",
    "\n",
    "\n",
    "# 検索結果を返す関数の作成\n",
    "def get_search_result(question):\n",
    "    TAVILY_API_KEY = os.environ['TAVILY_API_KEY']\n",
    "    response = TavilyClient(api_key=TAVILY_API_KEY).search(question)\n",
    "    glog(f\"Invoked get_search_result tool. {question=}\")\n",
    "\n",
    "    # Tavily のレスポンスの構造については以下の通り\n",
    "    # response= {\n",
    "    #     \"results\": [\n",
    "    #         {\n",
    "    #             \"title\": \"TITLE01\",\n",
    "    #             \"url\": \"URL01\",\n",
    "    #             \"content\": \"CONTENT01 ...（略）\",\n",
    "    #             \"score\": 0.9987649,\n",
    "    #             \"raw_content\": None\n",
    "    #         }, ...\n",
    "    #     ]\n",
    "    # }\n",
    "\n",
    "    return json.dumps({\"result\": response[\"results\"]})\n",
    "\n",
    "\n",
    "def local_calc(expression):\n",
    "    return Calculator.calc(expression)\n",
    "\n",
    "\n",
    "### =======================================\n",
    "### それなりに文字列から安全に計算を行う計算機クラス\n",
    "### =======================================\n",
    "\n",
    "import ast, operator\n",
    "class Calculator:\n",
    "    ALLOWED_OPS = {\n",
    "        ast.Add: operator.add,      # +\n",
    "        ast.Sub: operator.sub,      # -\n",
    "        ast.Mult: operator.mul,     # *\n",
    "        ast.Div: operator.truediv,  # /\n",
    "        ast.FloorDiv: operator.floordiv,  # //\n",
    "        ast.Mod: operator.mod,      # %\n",
    "        ast.Pow: operator.pow,      # **\n",
    "        ast.USub: operator.neg,     # -（単項マイナス）\n",
    "        ast.UAdd: operator.pos,     # +（単項プラス）\n",
    "    }\n",
    "\n",
    "    @classmethod\n",
    "    def calc(K, expression):\n",
    "        return json.dumps({ \"result\": K.calc_core(expression) })\n",
    "    \n",
    "    @classmethod\n",
    "    def calc_core(K, expression):\n",
    "        is_error = True\n",
    "        result = None\n",
    "        try:\n",
    "            tree = ast.parse(expression, mode='eval')\n",
    "            result = K.eval_node(tree.body)\n",
    "            is_error = False\n",
    "        except Exception as e:\n",
    "            result = e.value\n",
    "        finally:\n",
    "            result = [{\n",
    "                \"expression\": expression,\n",
    "                \"result\": result,\n",
    "                \"is_error\": is_error\n",
    "            }]\n",
    "            return result\n",
    "\n",
    "    @classmethod\n",
    "    def eval_node(K, node):\n",
    "        # 定数 (Python 3.8以降??)\n",
    "        if isinstance(node, ast.Constant):\n",
    "            return node.value\n",
    "        \n",
    "        # 二項演算\n",
    "        elif isinstance(node, ast.BinOp):\n",
    "            left, op_type, right = K.eval_node(node.left), type(node.op), K.eval_node(node.right)\n",
    "            if op_type in K.ALLOWED_OPS:\n",
    "                return K.ALLOWED_OPS[op_type](left, right)\n",
    "            else:\n",
    "                raise ValueError(f\"Not alloeed operator: {op_type}\")\n",
    "            \n",
    "        # 単項演算\n",
    "        elif isinstance(node, ast.UnaryOp):\n",
    "            operand, op_type = K.eval_node(node.operand), type(node.op)\n",
    "            if op_type in K.ALLOWED_OPS:\n",
    "                return K.ALLOWED_OPS[op_type](operand)\n",
    "            else:\n",
    "                raise ValueError(f\"Not allowed operator: {op_type}\")\n",
    "            \n",
    "        # その他は演算不可\n",
    "        else:\n",
    "            raise ValueError(f\"Not allowed node: {type(node)}\")\n",
    "\n",
    "\n",
    "### =======================================\n",
    "### 以下、ユーティリティクラスとなります\n",
    "### ---------------------------------------\n",
    "### ※ 中身は Lesson 10 と全く同じなのでそちらのレビューが通っていれば以下は特に再レビューは不要です\n",
    "### =======================================\n",
    "\n",
    "class OpenAIClientGenerator:\n",
    "\n",
    "    OPEN_API_ENV_NAME = \"API_KEY\"\n",
    "    \n",
    "    # この関数を呼び出すことで .env ファイルもしくは環境変数から OpenAI API をロードして\n",
    "    # OpenAI の client インスタンスを返します\n",
    "    # api_key_validation      ... True なら簡易的なキーのチェックを行います\n",
    "    # display_debug_messages  ... True ならデバッグメッセージを表示します\n",
    "    @classmethod\n",
    "    def generate(cls, api_key_validation=True, display_debug_messages=False):\n",
    "        return OpenAI(api_key=cls.__load_api_key(api_key_validation, display_debug_messages))\n",
    "\n",
    "\n",
    "    # この関数で OpenAI API のキーを読み取ります\n",
    "    # 1. 実行パスの ../.env が存在するならば API_KEY を環境変数としてロードして読み取る\n",
    "    # 2. 環境変数の API_KEY をロードして読み取る\n",
    "    # 3. API_KEY の中身の値が絶対ファイルパスならばその中身をそのままロードする\n",
    "    #    そうでないならば中身をそのまま API キーとして使う\n",
    "    # 4. キーの簡易的なフォーマットチェック\n",
    "    @classmethod\n",
    "    def __load_api_key(cls, api_key_validation, display_debug_messages):        \n",
    "        api_key = None\n",
    "\n",
    "        log = cls.get_logger(display_debug_messages)\n",
    "\n",
    "        # 1. ../.env を読み取る\n",
    "        env_file_path = Path().resolve().parent.resolve() / \".env\"\n",
    "        if env_file_path.is_file():\n",
    "            try:\n",
    "                from dotenv import load_dotenv\n",
    "                load_dotenv(env_file_path)\n",
    "                log(f\"Loaded .env environment variables correctly. env={env_file_path.resolve()}\")\n",
    "            except:\n",
    "                log(\"=== EXCEPTION ============\")\n",
    "                log(traceback.format_exc())\n",
    "                log(\"==========================\")\n",
    "                log(\"Found .env file but failed to load dotenv file! Please install python-dotenv module.\")\n",
    "        \n",
    "        # 2. API_KEY を読み取る\n",
    "        api_key = os.environ.get(cls.OPEN_API_ENV_NAME, None)\n",
    "\n",
    "        # 3. API_KEY の中身チェック\n",
    "        api_file_path = Path(api_key).expanduser()\n",
    "        if (api_file_path.is_absolute() and api_file_path.is_file()):\n",
    "            log(\"Found OpenAI API key file.\")\n",
    "            with open(api_file_path, \"r\") as f:\n",
    "                api_key = f.read().strip()\n",
    "\n",
    "        # 4. キーの簡易チェック\n",
    "        if api_key_validation:\n",
    "            if re.match(r\"^sk\\-.*$\", api_key) is None:\n",
    "                raise Exception(\"Failed to load api key!\")\n",
    "\n",
    "        return api_key\n",
    "\n",
    "    \n",
    "    # 簡易 logging クラス代わり、ロガーを入手するための関数\n",
    "    @classmethod\n",
    "    def get_logger(cls, display_debug_messages):\n",
    "        return cls.log_print if display_debug_messages else (lambda *arg, **kwargs: None)\n",
    "\n",
    "\n",
    "    # 簡易 logging クラス代わり、ロガーで印字する関数\n",
    "    @staticmethod\n",
    "    def log_print(msg, *args, **kwargs):\n",
    "        formated_msg = f\"[LOG] {msg}\"\n",
    "        print(formated_msg, *args, **kwargs)\n",
    "\n",
    "\n",
    "# ロギング用の関数 (デバッグ用に使います)\n",
    "glog = OpenAIClientGenerator.get_logger(DEBUG_FLAG)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
